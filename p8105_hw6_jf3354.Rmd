---
title: "p8105_hw6_jf3354"
author: Judy Fordjuoh
date: November 27, 2021
output: github_document
---

```{r, echo=FALSE}
library(tidyverse)
library(dplyr)
library(readxl)
library(modelr)
library(mgcv)
library(ggplot2)
library(patchwork)
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Question 1

```{r}
#Load and clean the data for regression analysis (i.e. convert numeric to factor where appropriate, check for missing data, etc.

bw = 
    read_csv("birthweight.csv") %>% 
 janitor::clean_names() %>% 
  mutate(
    babysex = as.factor(babysex),
    malform = as.factor(malform),
    frace = as.factor(frace),
    mrace = as.factor(mrace)
  ) #all the other variables are continuous so we won't convert them

#checking for NA's
purrr::map(bw, ~ sum(is.na(.)))
```

#For my model I included risk factors that I have learned in previous classes have have an affect on birthweight of a child, specifically contributing to low birthweight. In terms of behavioral risk factors, I included smoken because maternal smoking during pregnancy and the smoking intensity has been consistently related to low birthweight. In terms of preganncy specific factors, I included the mothers age at delivry(momage), the mothers weight at the delivery(delwt), mother's weight gain during pregnancy(wtgain), presence of malformations(malform), number of live births prior to this pregancy(parity), and previous number of low birth weight babies (pnumlbw) into the model. I also added an interaction model between mother's weight at delivery and weight bain during pregnanacy as they are dependent on each other. 

```{r}
#Propose a regression model for birthweight. This model may be based on a hypothesized structure for the factors that underly birthweight, on a data-driven model-building process, or a combination of the two. Describe your modeling process and show a plot of model residuals against fitted values – use add_predictions and add_residuals in making this plot.

fitted_model_1 = lm(bwt ~ smoken + momage + delwt + wtgain + malform + parity + pnumlbw + delwt*wtgain, data = bw)

summary(fitted_model_1)

bw %>% 
  modelr::add_residuals(fitted_model_1) %>%
  modelr::add_predictions(fitted_model_1) %>% 
  ggplot(aes(x = pred, y = resid)) + 
  geom_point(alpha = 0.3) +
  geom_smooth(se = TRUE, color = "red", method = "lm") +
  labs(
    title = "Predicted vs. Residuals",
    x = "Predicted",
    y = "Residuals") +
  theme(plot.title = element_text(hjust = 0.5))

```
# Prediction values seem to be concentrated between 2750 and 3500 while the residual values seem to aggregate between -1000 and 900. Now we will compared our model to two other models: 1. one predicting birth weight using length at birth baby and gestational age as the only main effects and 2.head circumference, length at birth baby, sex, and all interactions beteween these 3 variables to predict birth weight. 
```{r}
#Model 1: only baby length and gestational age
provided_model1 = lm(bwt~ blength + gaweeks, data = bw) 
summary(provided_model1)

bw %>% 
  modelr::add_residuals(provided_model1) %>% 
  modelr::add_predictions(provided_model1) %>%
  ggplot(aes(x = pred, y = resid)) + 
  geom_point(alpha = .3) +
  labs(
    title = "Model 1: Body Length and Gestational Age Main Effects Only",
    x = "Predictions",
    y = "Residuals") +
  theme(plot.title = element_text(hjust = 0.5))

#Model 2: head circumference, length at birth baby, sex, and all interactions
provided_model2 = lm(bwt~ blength + babysex + bhead + blength*babysex*bhead + blength*babysex + blength*bhead + babysex*bhead, data = bw) 
summary(provided_model2)

bw %>% 
  modelr::add_residuals(provided_model2) %>% 
  modelr::add_predictions(provided_model2) %>%
  ggplot(aes(x = pred, y = resid)) + 
  geom_point(alpha = .3) +
  labs(
    title = "Model 2: Body Length, Head Circumference, 
    Baby Sex, and All Possible Interactions",
    x = "Predictions",
    y = "Residuals") +
  theme(plot.title = element_text(hjust = 0.5))
```

```{r}
#Make this comparison in terms of the cross-validated prediction error; use crossv_mc and functions in purrr as appropriate.
cv_df =
  crossv_mc(bw, 100)

cv_df %>% pull(train) %>% .[[1]] %>% as_tibble
cv_df %>% pull(test) %>% .[[1]] %>% as_tibble

cv_df =
  cv_df %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)) 

#Now I have my testing and training datasets and have to fit my models and obtain the RMSEs using mutate + map

cv_df = 
  cv_df %>% 
  mutate(
    fitted_model_1  = map(train, ~lm(bwt ~ smoken + momage + delwt + wtgain + malform + parity + pnumlbw + delwt*wtgain, data = .x)),
    provided_model1  = map(train, ~lm(bwt~ blength + gaweeks, data = .x)),
    provided_model2  = map(train, ~lm(bwt~ blength + babysex + bhead + blength*babysex*bhead + blength*babysex + blength*bhead + babysex*bhead, data = .x))) %>% 
mutate(
    rmse_1 = map2_dbl(fitted_model_1, test, ~rmse(model = .x, data = .y)),
    rmse_2 = map2_dbl(provided_model1, test, ~rmse(model = .x, data = .y)),
    rmse_3 = map2_dbl(provided_model2, test, ~rmse(model = .x, data = .y)))

cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  mutate(model = recode(model,
                        "1" = "My Model",
                        "2" = "Main Effects Model",
                        "3" = "All Possible 
                        Interactions Model")) %>%
  ggplot(aes(x = model, y = rmse, fill = model)) + 
  geom_violin() +
  labs(
    title = "Cross Validation of Average RSME for Each Model",
    x = "Model",
    y = "RSME"
  ) 
```

#We can see that my model has the highest RMSE on average making it the worst predictor model out of the 3 discussed. The all possible interactions model has the lowest RMSE on average making it the best predictor model out of the 3. The distribution of my model’s violin plot has a similar shape to the main effects model except mine is wider and stumpy. If I would redo this, I would maybe reduce the amount of variables in the model and include more interaction terms because there is some form of dependence on other variables or effect modifiying for some variables. 

## Question 2

```{r}
#Code from the website
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

```{r}
#We are doing a simple linear regression with tmax as the response and tmin as the predictor

#Use 5000 bootstrap samples and, for each bootstrap sample, produce estimates of these two quantities (the r squared and the log(beta0*beta1)). Plot the distribution of your estimates, and describe these in words.

#writing function    
sample = function(df) {
  sample_frac(df, replace = TRUE)
}

#from bootstrapping lecture
boot_straps = 
  data_frame(
    strap_number = 1:5000,
    sample = rerun(5000, sample(weather_df))
  )

```

```{r}
#ANALYZING R SQUARED
bootstraps_results = 
  boot_straps %>%
  mutate(
    models = map(.x = sample, ~lm(tmax ~ tmin, data = .x)),
    results_1 = map(models, broom::glance) #rsquare 
    ) %>%
  select(strap_number, results_1) %>% 
  unnest(results_1)

bootstraps_results %>%
  ggplot(aes(x = adj.r.squared)) +
  geom_density() +
  labs(
        title = "Distribution of the Adjusted R Squared",
        x = "R Squared",
        y = "Density" 
    ) +
  theme(plot.title = element_text(hjust = 0.5))

#95% confidence intervals
bootstraps_results %>% 
  pull(adj.r.squared) %>% 
  quantile(c(0.025, 0.975))
```
#From the plot of adjusted R square, we can see that its distribution looks like a normal distribution, with the highest peaks around 0.911-0.912.The 95% CI of adjusted R square is: (0.895-0.927).


```{r}
#ANALYZING log(beta0*beta1)

bootstrap_results2 =
  boot_straps %>% 
  mutate(
    models = map(sample, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::tidy)) %>% 
select(strap_number, results) %>% #still in list form
  unnest(results) %>% #flattens it back out into regular columns
  select(term, estimate) %>% 
  pivot_wider(
    names_from = term,
    values_from = estimate
  ) %>% #there is an intercept and tmin column but everything is squisjed so unnest it
  unnest(cols = c(`(Intercept)`, tmin)) %>% #flattens it back out into regular columns
  rename(
    beta_0 = "(Intercept)",
    beta_1 = tmin
  ) %>% 
 mutate(
    log_function = log(beta_0*beta_1)
  )

bootstrap_results2 %>%
  ggplot(aes(x = log_function)) +
  geom_density() +
  labs(
        title = "Distribution of Log(Beta0*Beta1)",
        x = "Log(Beta0*Beta1)",
        y = "Density" 
    ) +
  theme(plot.title = element_text(hjust = 0.5))

#95% confidence intervals
bootstrap_results2 %>% 
  pull(log_function) %>% 
  quantile(c(0.025, 0.975))

```
#From the plot of the distrubution of log(beta0*beta1), we can see that the distribution of the log is normal distribution, with the highest peaks around 2.015-2.020. The 95% CI of log(beta0*beta1) is: (1.964-2.058).


